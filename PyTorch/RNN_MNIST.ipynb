{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn  # All neural network modules, nn.Linear, nn.Conv2d, BatchNorm, Loss functions\n",
    "import torch.optim as optim  # For all Optimization algorithms, SGD, Adam, etc.\n",
    "import torch.nn.functional as F  # All functions that don't have any parameters\n",
    "from torch.utils.data import (\n",
    "    DataLoader,\n",
    ")  # Gives easier dataset managment and creates mini batches\n",
    "import torchvision.datasets as datasets  # Has standard datasets we can import in a nice way\n",
    "import torchvision.transforms as transforms  # Transformations we can perform on our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "input_size = 28\n",
    "hidden_size = 256\n",
    "num_layers = 1\n",
    "num_classes = 10\n",
    "sequence_length = 28\n",
    "learning_rate = 0.01\n",
    "batch_size = 64\n",
    "num_epochs = 5\n",
    "\n",
    "train_dataset = datasets.MNIST(\n",
    "    root=\"dataset/\", train=True, transform=transforms.ToTensor(), download=True\n",
    ")\n",
    "\n",
    "test_dataset = datasets.MNIST(\n",
    "    root=\"dataset/\", train=False, transform=transforms.ToTensor(), download=True\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 60000\n",
       "    Root location: dataset/\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: ToTensor()"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "images,labels=next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "images.shape   ## batch of 64 images, 1 channel, 28X28\n",
    "print(images.squeeze(1).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self,input_size,hidden_size, num_layers, num_classes):\n",
    "        super(RNN,self).__init__()\n",
    "        self.input_size=input_size\n",
    "        self.hidden_size=hidden_size\n",
    "        self.num_layers=num_layers\n",
    "        \n",
    "        self.rnn=nn.GRU(input_size,hidden_size,num_layers,batch_first=True)   ##Instead of GRU, simple RNN can be used as below\n",
    "        #self.rnn=nn.RNN(input_size,hidden_size,num_layers,batch_first=True)\n",
    "        self.fc=nn.Linear(sequence_length*hidden_size, num_classes)    ## The output of RNN is suposed to be this, check \n",
    "        \n",
    "    def forward(self,x):\n",
    "        #h0=torch.zeros(batch_size,num_layers,hidden_size)  ## This is supposed to be the dimension of hidden, check docs\n",
    "        ##We can omit the above line since pytorch implicitly can define the initial hidden state\n",
    "        out, _=self.rnn(x)\n",
    "        out= out.reshape(out.size(0),-1)   ## Since the output of RNN is : Batch X seq_length X hidden_size\n",
    "        out=self.fc(out)\n",
    "        return out\n",
    "    \n",
    "                \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 100 0.5416555697470904\n",
      "1 200 0.30151759488508106\n",
      "1 300 0.24489514326676726\n",
      "1 400 0.22135506493970752\n",
      "1 500 0.2646946180798113\n",
      "1 600 0.21628798396792262\n",
      "1 700 0.2142199614678975\n",
      "1 800 0.2212664064054843\n",
      "1 900 0.2815736058715265\n",
      "2 100 0.18577722580754197\n",
      "2 200 0.17462258572340944\n",
      "2 300 0.15955362594540928\n",
      "2 400 0.21128770615527173\n",
      "2 500 0.18967950030229985\n",
      "2 600 0.1538682202711425\n",
      "2 700 0.559040157776326\n",
      "2 800 0.9157516873627901\n",
      "2 900 0.6677597797103226\n",
      "3 100 0.345773831109982\n",
      "3 200 0.34393676704110476\n",
      "3 300 0.297503183817189\n",
      "3 400 0.2457331905490719\n",
      "3 500 0.23034094353410184\n",
      "3 600 0.24112510446459054\n",
      "3 700 0.2279403104887274\n",
      "3 800 0.22646140249766178\n",
      "3 900 0.22951832945095701\n",
      "4 100 0.16941715283588565\n",
      "4 200 0.14392549726556353\n",
      "4 300 0.13445125032935265\n",
      "4 400 0.19185534232083457\n",
      "4 500 0.1860054040304658\n",
      "4 600 0.23072998011635718\n",
      "4 700 0.24317138892874937\n",
      "4 800 0.1994385685805173\n",
      "4 900 0.21358676996354917\n",
      "5 100 0.13295625841387845\n",
      "5 200 0.15030163708644978\n",
      "5 300 0.15871925972690407\n",
      "5 400 0.13013842230669526\n",
      "5 500 0.1341771308694115\n",
      "5 600 0.18739961536487498\n",
      "5 700 0.20681695928364208\n",
      "5 800 0.16218475430976412\n",
      "5 900 0.17201291728531942\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = RNN(input_size, hidden_size, num_layers, num_classes)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "for epoch in range(num_epochs):\n",
    "    totalloss=0\n",
    "    for i,(data,targets) in enumerate(train_loader):\n",
    "        data=data.squeeze(1)   ##Get rid of channels dimension since our RNN does not expect it\n",
    "        \n",
    "        scores=model(data)\n",
    "        loss = criterion(scores, targets)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        totalloss+=loss.item()\n",
    "        if(i%100==99):\n",
    "            print(epoch+1, i+1, totalloss/100)   ##Print loss every 100 mini batches\n",
    "            totalloss=0\n",
    "            \n",
    "        \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets see how our model behaves on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  97.28\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        images=images.squeeze(1)\n",
    "        outputs = model(images)\n",
    "        correct+=outputs.argmax(dim=1).eq(labels).sum().item()\n",
    "    total=len(test_dataset)\n",
    "    print('Accuracy: ',correct*100/total )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "image,label=next(iter(test_loader))\n",
    "image[0].shape\n",
    "img=image[0]\n",
    "### Lets test the output for 1 image, as you see below img[0] is a label of 3, our model should predict 3 also"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4)\n"
     ]
    }
   ],
   "source": [
    "print(label[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-28.7556, -16.9997,  -7.2758,  -1.7043,  26.7961,  -1.8823, -18.4477,\n",
      "          -5.0595,  -2.9458,  10.8903]], grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "pred=model(img.squeeze(1))\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.argmax(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ABove argmax show that index 4 is highest, means the label it predicted is also 4. Which is what we expected"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
